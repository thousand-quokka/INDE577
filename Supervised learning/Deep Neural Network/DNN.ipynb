{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The Fashion MNIST dataset is a popular benchmark for image classification tasks. Deep Neural Networks (DNNs) can be applied to this dataset using TensorFlow, a high-level library for building and training deep learning models, or by building a DNN from scratch using Python. DNNs have achieved impressive results on the Fashion MNIST dataset, with state-of-the-art models achieving over 99% accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Network (manual)\n",
    "\n",
    "The  `MultilayerPerceptron`  class represents a neural network with a given number of layers and activation function. Its weights and biases are randomly initialized upon creation. It includes methods for forward propagation, calculating the mean squared error, and stochastic and mini-batch gradient descent for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilayerPerceptron():\n",
    "    def __init__(self, layers = [784, 60, 60, 10], actFun_type='relu'):\n",
    "        self.actFun_type = actFun_type\n",
    "        self.layers = layers\n",
    "        self.L = len(self.layers)\n",
    "        self.W =[[0.0]]\n",
    "        self.B = [[0.0]]\n",
    "        for i in range(1, self.L):\n",
    "            w_temp = np.random.randn(self.layers[i], self.layers[i-1]) * np.sqrt(2/self.layers[i-1])\n",
    "            b_temp = np.random.randn(self.layers[i], 1) * np.sqrt(2/self.layers[i-1])\n",
    "\n",
    "            self.W.append(w_temp)\n",
    "            self.B.append(b_temp)\n",
    "\n",
    "    def reset_weights(self, layers = [784, 60, 60, 10]):\n",
    "        self.layers = layers\n",
    "        self.L = len(self.layers)\n",
    "        self.W = [[0.0]]\n",
    "        self.B = [[0.0]]\n",
    "        for i in range(1, self.L):\n",
    "            w_temp = np.random.randn(self.layers[i], self.layers[i-1])*np.sqrt(2/self.layers[i-1])\n",
    "            b_temp = np.random.randn(self.layers[i], 1)*np.sqrt(2/self.layers[i-1])\n",
    "\n",
    "            self.W.append(w_temp)\n",
    "            self.B.append(b_temp)\n",
    "\n",
    "    def forward_pass(self, p, predict_vector = False):\n",
    "        Z =[[0.0]]\n",
    "        A = [p[0]]\n",
    "        for i in range(1, self.L):\n",
    "            z = (self.W[i] @ A[i-1]) + self.B[i]\n",
    "            a = self.actFun(z, self.actFun_type)\n",
    "            Z.append(z)\n",
    "            A.append(a)\n",
    "\n",
    "        if predict_vector == True:\n",
    "            return A[-1]\n",
    "        else:\n",
    "            return Z, A\n",
    "\n",
    "    def mse(self, a, y):\n",
    "        return .5*sum((a[i]-y[i])**2 for i in range(10))[0]\n",
    "\n",
    "    def MSE(self, data):\n",
    "        c = 0.0\n",
    "        for p in data:\n",
    "            a = self.forward_pass(p, predict_vector=True)\n",
    "            c += self.mse(a, p[1])\n",
    "        return c/len(data)\n",
    "\n",
    "    def actFun(self, z, type):\n",
    "        if type == 'tanh':\n",
    "            return np.tanh(z)\n",
    "        elif type == 'sigmoid':\n",
    "            return 1.0 / (1.0 + np.exp(-z))\n",
    "        elif type == 'relu':\n",
    "            return np.maximum(0, z)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def diff_actFun(self, z, type):\n",
    "        if type == 'tanh':\n",
    "            return 1.0 - (np.tanh(z))**2\n",
    "        elif type == 'sigmoid':\n",
    "            return self.actFun(z, type) * (1-self.actFun(z, type))\n",
    "        elif type == 'relu':\n",
    "            return np.where(z > 0, 1.0, 0)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def deltas_dict(self, p):\n",
    "        Z, A = self.forward_pass(p)\n",
    "        deltas = dict()\n",
    "        deltas[self.L-1] = (A[-1] - p[1])*self.diff_actFun(Z[-1], self.actFun_type)\n",
    "        for l in range(self.L-2, 0, -1):\n",
    "            deltas[l] = (self.W[l+1].T @ deltas[l+1]) *self.diff_actFun(Z[l], self.actFun_type)\n",
    "\n",
    "        return A, deltas\n",
    "\n",
    "    def stochastic_gradient_descent(self, data, alpha = 0.04, epochs = 3):\n",
    "        print(f\"Initial Cost = {self.MSE(data)}\")\n",
    "        for k in range(epochs):\n",
    "            for p in data:\n",
    "                A, deltas = self.deltas_dict(p)\n",
    "                for i in range(1, self.L):\n",
    "                    self.W[i] = self.W[i] - alpha*deltas[i]@A[i-1].T\n",
    "                    self.B[i] = self.B[i] - alpha*deltas[i]\n",
    "        print(f\"{k} Cost = {self.MSE(data)}\")\n",
    "\n",
    "\n",
    "    def mini_batch_gradient_descent(self, data, batch_size = 15, alpha = 0.04, epochs = 3):\n",
    "        print(f\"Initial Cost = {self.MSE(data)}\")\n",
    "        data_length = len(data)\n",
    "        for k in range(epochs):\n",
    "            for j in range(0, data_length-batch_size, batch_size):\n",
    "                delta_list = []\n",
    "                A_list = []\n",
    "                for p in data[j:j+batch_size]:\n",
    "                    A, deltas = self.deltas_dict(p)\n",
    "                    delta_list.append(deltas)\n",
    "                    A_list.append(A)\n",
    "\n",
    "                for i in range(1, self.L):\n",
    "                    self.W[i] = self.W[i] - (alpha/batch_size)*sum(da[0][i]@da[1][i-1].T for da in zip(delta_list, A_list))\n",
    "                    self.B[i] = self.B[i] - (alpha/batch_size)*sum(deltas[i] for deltas in delta_list)\n",
    "            print(f\"{k} Cost = {self.MSE(data)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our approach involves training MLPs using mini-batch gradient descent with three different activation functions - sigmoid, hyperbolic tangent, and rectified linear - and subsequently evaluating their respective performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Check the shape of the training set\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].flatten().reshape(28*28, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for x in X_train:\n",
    "    X.append(x.flatten().reshape(28*28, 1))\n",
    "\n",
    "# Y will temp store one-hot encoded label vectors\n",
    "Y = []\n",
    "for y in y_train:\n",
    "    temp_vec = np.zeros((10, 1))\n",
    "    temp_vec[y][0] = 1.0\n",
    "    Y.append(temp_vec)\n",
    "\n",
    "# Our data will be stored as a list of tuples. \n",
    "train_data = [p for p in zip(X, Y)]\n",
    "\n",
    "# the same method to deal with test data\n",
    "X = []\n",
    "for x in X_test:\n",
    "  X.append(x.flatten().reshape(784, 1))\n",
    "\n",
    "Y = []\n",
    "for y in y_test:\n",
    "    temp_vec = np.zeros((10, 1))\n",
    "    temp_vec[y][0] = 1.0\n",
    "    Y.append(temp_vec)\n",
    "\n",
    "test_data = [p for p in zip(X, Y)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Tangent Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Cost = 1.7341290435945995\n",
      "0 Cost = 0.17826196518565707\n",
      "1 Cost = 0.15667174315727325\n",
      "2 Cost = 0.14571188247337352\n",
      "3 Cost = 0.1383040023269899\n",
      "4 Cost = 0.1326546392369999\n"
     ]
    }
   ],
   "source": [
    "model_tanh = MultilayerPerceptron(layers=[784, 60, 60, 10], actFun_type='tanh')\n",
    "model_tanh.mini_batch_gradient_descent(train_data, batch_size = 16, alpha = 0.01, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model using hyperbolic tangent activation function's MSE is 0.1397961373789975\n"
     ]
    }
   ],
   "source": [
    "print(\"Model using hyperbolic tangent activation function's MSE is\", model_tanh.MSE(test_data))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Cost = 1.3618389636354724\n",
      "0 Cost = 0.21738571159002634\n",
      "1 Cost = 0.20214644585721991\n",
      "2 Cost = 0.1944401555426904\n",
      "3 Cost = 0.1888415068724031\n",
      "4 Cost = 0.18405408978394575\n"
     ]
    }
   ],
   "source": [
    "model_relu = MultilayerPerceptron(layers=[784, 100, 100, 10], actFun_type='relu')\n",
    "model_relu.mini_batch_gradient_descent(train_data, batch_size = 16, alpha = 0.01, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model using ReLU activation function's MSE is 0.19443326671756814\n"
     ]
    }
   ],
   "source": [
    "print(\"Model using ReLU activation function's MSE is\", model_relu.MSE(test_data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Cost = 1.2768092705260428\n",
      "0 Cost = 0.44020822655048897\n",
      "1 Cost = 0.4210638874979604\n",
      "2 Cost = 0.3824566624800973\n",
      "3 Cost = 0.34280318356137746\n",
      "4 Cost = 0.31189562079047173\n"
     ]
    }
   ],
   "source": [
    "model_sig = MultilayerPerceptron(layers=[784, 100, 100, 10], actFun_type='sigmoid')\n",
    "model_sig.mini_batch_gradient_descent(train_data, batch_size = 16, alpha = 0.01, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model using sigmoid activation function's MSE is 0.31275587810097416\n"
     ]
    }
   ],
   "source": [
    "print(\"Model using sigmoid activation function's MSE is\", model_sig.MSE(test_data))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the MSE, we could see the tangent activation function has the best performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Network (tensorflow)\n",
    "\n",
    "In this part, we apply the package tensorflow to build our DNN model. The following code snippet appears to be implementing a neural network model using the Multilayer Perceptron (MLP) architecture, with a total of 4 layers - an input layer of 784 neurons, followed by two hidden layers of 60 neurons each, and an output layer of 10 neurons. The activation function used in this MLP model is the hyperbolic tangent (tanh) function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 6s 2ms/step - loss: 0.4944 - accuracy: 0.8238\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3690 - accuracy: 0.8652\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3359 - accuracy: 0.8765\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3114 - accuracy: 0.8855\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2949 - accuracy: 0.8918\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2788 - accuracy: 0.8960\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2665 - accuracy: 0.9010\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2532 - accuracy: 0.9056\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2456 - accuracy: 0.9070\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2358 - accuracy: 0.9108\n",
      "313/313 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the Fashion MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Reshape the input data\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# Normalize the input data\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "# Convert the target labels to one-hot encoded vectors\n",
    "num_classes = 10\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "# Define the deep neural network architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model with categorical cross-entropy loss and Adam optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model on the training set\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.016861444\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean squared error on the test set\n",
    "test_mse = np.mean(np.square(test_predictions - y_test))\n",
    "\n",
    "print(\"Test MSE:\", test_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n",
      "Predicted Label: 9 ( Ankle boot )\n",
      "True Label: 9 ( Ankle boot )\n"
     ]
    }
   ],
   "source": [
    "image_index = 0\n",
    "plt.imshow(x_test[image_index].reshape(28, 28), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# Make a prediction on the image\n",
    "image = x_test[image_index].reshape(1, 784)\n",
    "prediction = model.predict(image)\n",
    "predicted_label = np.argmax(prediction)\n",
    "\n",
    "# Define the class names\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "# Show the predicted and true labels with their names\n",
    "true_label = np.argmax(y_test[image_index])\n",
    "predicted_name = class_names[predicted_label]\n",
    "true_name = class_names[true_label]\n",
    "print(\"Predicted Label:\", predicted_label, \"(\", predicted_name, \")\")\n",
    "print(\"True Label:\", true_label, \"(\", true_name, \")\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n",
      "Predicted Label: 1 ( Trouser )\n",
      "True Label: 1 ( Trouser )\n"
     ]
    }
   ],
   "source": [
    "# Show an image from the test set\n",
    "image_index = 3\n",
    "plt.imshow(x_test[image_index].reshape(28, 28), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# Make a prediction on the image\n",
    "image = x_test[image_index].reshape(1, 784)\n",
    "prediction = model.predict(image)\n",
    "predicted_label = np.argmax(prediction)\n",
    "\n",
    "# Show the predicted label with its name\n",
    "true_label = np.argmax(y_test[image_index])\n",
    "predicted_name = class_names[predicted_label]\n",
    "true_name = class_names[true_label]\n",
    "print(\"Predicted Label:\", predicted_label, \"(\", predicted_name, \")\")\n",
    "print(\"True Label:\", true_label, \"(\", true_name, \")\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The DNN model implemented for the Fashion MNIST dataset achieved high accuracy on both the training and validation sets, indicating good generalization. The model was able to classify the different fashion items with high accuracy, with an overall accuracy of around 90%. The model also demonstrated good convergence during training, with the training and validation loss decreasing steadily over time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
